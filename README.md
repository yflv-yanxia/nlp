# nlp

## RE
[Boost.Regex]<br>
[hyperscan]<br>
[QRegExp]<br>
[python.re]<br>

## LAC

### pretrain models
[thulac]<br>
[baidu/lac]<br>
[HIT-SCIR/ltp](https://github.com/HIT-SCIR/ltp)<br>
[spacy](https://spacy.io/)<br>
[stanza](https://stanfordnlp.github.io/stanza/)<br>
[hanlp]<br>


## Machine Reading Comprehension
[Improving Machine Reading Comprehension with Single-choice Decision and Transfer Learning](https://arxiv.org/abs/2011.03292) -tencent, arxiv2020<br>
[DUMA: Reading Comprehension with Transposition Thinking](https://arxiv.org/abs/2001.09415) -huawei, arxiv2020<br>
[DCMN+: Dual co-matching network for multi-choice reading comprehension](https://ojs.aaai.org/index.php/AAAI/article/view/6502) -cloudwalk, AAAI2020<br>
[Albert: A lite bert for self-supervised learning of language representations](https://arxiv.org/abs/1909.11942) -google, ICLR2020<br>
[Dual co-matching network for multi-choice reading comprehension](https://arxiv.org/abs/1901.09381) -cloudwalk, arxiv2019<br>
[Option comparison network for multiple-choice reading comprehension](https://arxiv.org/abs/1903.03033) -tencent, arxiv2019<br>
[Neural Machine Reading Comprehension: Methods and Trends](https://www.mdpi.com/2076-3417/9/18/3698) -S Liu, AppliedSciences2019<br>
[Applying deep learning to answer selection: A study and an open task](https://ieeexplore.ieee.org/abstract/document/7404872) -IBM, ASRU2015<br>

### databse
[DREAM](https://dataset.org/dream/)<br>
[RACE](http://www.qizhexie.com/data/RACE_leaderboard.html)<br>
[SQuAD2.0]<br>
[ARC]<br>
[CoQA]<br>

## NER

### database
Ontonotes release 4.0/5.0<br>
[MSRA, Word segmentation and named entity recognition](https://huggingface.co/datasets/viewer/?dataset=msra_ner)<br>
[Weibo NER, recognition for Chinese social media with jointly trained embeddings](https://huggingface.co/datasets/viewer/?dataset=weibo_ner)<br>
[人民日报](https://huggingface.co/datasets/viewer/?dataset=peoples_daily_ner)<br>
[BosonNLP_NER_6C](https://bosonnlp.com/resources/BosonNLP_NER_6C.zip)<br>
[CCKS2017/2018/2019/2020电子病历实体标注](https://www.biendata.com/competition/ccks_2020_2_1/)<br>
[WikiANN/PAN-X](https://huggingface.co/datasets/viewer/?dataset=wikiann)<br>
[XGLUE](https://huggingface.co/datasets/viewer/?dataset=xglue)<br>
[CLUENER2020](https://github.com/CLUEbenchmark/CLUENER2020)<br>

### pretrain models
[baidu/ERNIE](https://github.com/PaddlePaddle/ERNIE)<br>
[baidu/lac](https://github.com/baidu/lac)<br>
[HIT-SCIR/ltp](https://github.com/HIT-SCIR/ltp)<br>
[spacy](https://spacy.io/)<br>
[stanza](https://stanfordnlp.github.io/stanza/)<br>
[腾讯UER](https://github.com/dbiir/UER-py/blob/master/README_ZH.md)<br>
[CLUEPretrainedModels](https://github.com/CLUEbenchmark/CLUEPretrainedModels)<br>
[Chinese-BERT-wwm](https://github.com/ymcui/Chinese-BERT-wwm)<br>
[google](https://github.com/google-research/bert)<br>




## sentence relation

## database
### dict
CLUECorpus2020
Google原始中文词表


### pretrain 
[CLUECorpus2020](https://github.com/CLUEbenchmark/CLUECorpus2020)<br>
[brightmart](https://github.com/brightmart/nlp_chinese_corpus)<br>
人民日报1998版本<br>
人民日报2014版本<br>


### CLUE
[中文医疗信息处理挑战榜CBLUE](https://tianchi.aliyun.com/specials/promotion/2021chinesemedicalnlpleaderboardchallenge), [database](https://tianchi.aliyun.com/dataset/dataDetail?dataId=95414)<br>


### QA
#### english
CLUE benchmark
google, Natural Questions: a Benchmark for Question Answering Research

#### chinese
哈工大、讯飞CMRC
DRCD

### cls
CLUE benchmark
清华大学开源的文本分类数据集THUCTC<br>




## labeling tools
YEDDA<br>






